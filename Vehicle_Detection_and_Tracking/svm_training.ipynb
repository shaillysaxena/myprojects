{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from skimage.feature import hog\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "from moviepy.editor import *\n",
    "# assigning a random seed so that the results are reproducible\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vehicle images found:  8792\n",
      "Number of non-vehicle images found:  8968\n"
     ]
    }
   ],
   "source": [
    "# images are divided into vehicles and non-vehicles folders and each contain more subfolders\n",
    "# first extract all cars images\n",
    "basedir = 'vehicles/'\n",
    "image_types = os.listdir(basedir)\n",
    "cars= []\n",
    "for imtype in image_types:\n",
    "    cars.extend(glob.glob(basedir+imtype+'/*'))\n",
    "    \n",
    "print('Number of vehicle images found: ', len(cars))\n",
    "\n",
    "# extract all non-car images\n",
    "basedir = 'non-vehicles/'\n",
    "image_types = os.listdir(basedir)\n",
    "notcars= []\n",
    "for imtype in image_types:\n",
    "    notcars.extend(glob.glob(basedir+imtype+'/*'))\n",
    "    \n",
    "print('Number of non-vehicle images found: ', len(notcars))\n",
    "# write these files \n",
    "with open(\"cars.txt\", \"w\") as f:\n",
    "    for fn in cars:\n",
    "        f.write(fn+'\\n')\n",
    "with open(\"noncars.txt\", \"w\") as f:\n",
    "    for fn in notcars:\n",
    "        f.write(fn+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, visualise=True, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block),\n",
    "                       transform_sqrt=False, visualise=False, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to compute binned color features\n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    color1 = cv2.resize(img[:, :, 0], size).ravel()\n",
    "    color2 = cv2.resize(img[:, :, 1], size).ravel()\n",
    "    color3 = cv2.resize(img[:, :, 2], size).ravel()\n",
    "    # Return the feature vector\n",
    "    return np.hstack((color1, color2, color3))\n",
    "\n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial(), color_hist() and hog\n",
    "def extract_features(imgs, color_space='YCrCb', orient=9, pix_per_cell=8, cell_per_block=2, \n",
    "                     hog_channel=0, spatial_size=(32, 32),\n",
    "                     hist_bins=32, spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        image_features = []\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)\n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            image_features.append(spatial_features)\n",
    "        \n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            image_features.append(hist_features)\n",
    "        \n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel],\n",
    "                                        orient, pix_per_cell, cell_per_block,\n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient,\n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            \n",
    "            # Append the new feature vector to the features list\n",
    "            image_features.append(hog_features)\n",
    "        features.append(np.concatenate(image_features))\n",
    "        \n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train the Linear Support Vector Classifier\n",
    "def train(cars, notcars):\n",
    "    color_space = 'YCrCb'\n",
    "    orient = 9\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    hog_channel = 'ALL'\n",
    "    spatial_size = (32, 32)\n",
    "    hist_bins = 32\n",
    "    spatial_feat = True\n",
    "    hist_feat = True\n",
    "    hog_feat = True\n",
    "    car_features = extract_features(cars, color_space, orient, pix_per_cell, cell_per_block, \n",
    "                                    hog_channel, spatial_size, hist_bins, spatial_feat, \n",
    "                                    hist_feat, hog_feat)\n",
    "    non_car_features = extract_features(notcars, color_space, orient, pix_per_cell, \n",
    "                                        cell_per_block, hog_channel, spatial_size,\n",
    "                                        hist_bins, spatial_feat, hist_feat, hog_feat)\n",
    "    print(\"features extracted\")\n",
    "    \n",
    "    # in an image we are mostly going to find a lot of non-cars elements and\n",
    "    # few of cars. If we use balanced data, our data might start predicting\n",
    "    # more cars than needed. So, we need to 'balance' our dataset in a way\n",
    "    # that the classifier sees more non-car samples than car samples but not\n",
    "    # so less that it cannot learn the cars at all. One way of doing this in\n",
    "    # machine learning is to oversample one class that is expected more to be\n",
    "    #  seen in real scenario. We can double the sample space of non-cars dataset\n",
    "    X = np.vstack((car_features,\n",
    "                   non_car_features,\n",
    "                   non_car_features\n",
    "                  )).astype(np.float64)\n",
    "    print(X.shape)\n",
    "    # assigning labels to both classes where cars = 1 and non-cars = 0\n",
    "    # and also accommodating for the fact that the non-car elements are\n",
    "    # oversampled\n",
    "    y = np.hstack((np.ones(len(car_features)),\n",
    "                   np.zeros(2*len(non_car_features))))\n",
    "    print(\"Shape of data: \", X.shape)\n",
    "    print(\"Shape of labels: \", y.shape)\n",
    "    # normalizing the training set\n",
    "    scalar = StandardScaler()\n",
    "    # fitting the scalar to training data\n",
    "    scalar.fit(X)\n",
    "    # transforming the data according to the scalar\n",
    "    normalized_X = scalar.transform(X)\n",
    "\n",
    "    # split the dataset into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(normalized_X, y, test_size=0.2)\n",
    "    print(\"Shape of training data: \", X_train.shape)\n",
    "    print(\"Shape of train labels: \", y_train.shape)\n",
    "    print(\"Shape of test data: \", X_test.shape)\n",
    "    print(\"Shape of test labels: \", y_test.shape)\n",
    "    clf = LinearSVC()\n",
    "    # fit the classifier to the training data\n",
    "    # Check the training time for the SVC\n",
    "    t = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print(round(t2 - t, 2), 'Seconds to train SVC...')\n",
    "    # Check the score of the SVC\n",
    "    print('Test Accuracy of SVC = ', round(clf.score(X_test, y_test), 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features extracted\n",
      "(26728, 8460)\n",
      "Shape of data:  (26728, 8460)\n",
      "Shape of labels:  (26728,)\n",
      "Shape of training data:  (21382, 8460)\n",
      "Shape of train labels:  (21382,)\n",
      "Shape of test data:  (5346, 8460)\n",
      "Shape of test labels:  (5346,)\n",
      "45.88 Seconds to train SVC...\n",
      "Test Accuracy of SVC =  0.9961\n"
     ]
    }
   ],
   "source": [
    "# training model on YCrCb\n",
    "train(cars, notcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_model(cars, notcars):\n",
    "    color_space = 'YCrCb'\n",
    "    orient = 9\n",
    "    pix_per_cell = 8\n",
    "    cell_per_block = 2\n",
    "    hog_channel = 'ALL'\n",
    "    spatial_size = (32, 32)\n",
    "    hist_bins = 32\n",
    "    spatial_feat = True\n",
    "    hist_feat = True\n",
    "    hog_feat = True\n",
    "    car_features = extract_features(cars, color_space, orient, pix_per_cell, cell_per_block, \n",
    "                                    hog_channel, spatial_size, hist_bins, spatial_feat, \n",
    "                                    hist_feat, hog_feat)\n",
    "    non_car_features = extract_features(notcars, color_space, orient, pix_per_cell, \n",
    "                                        cell_per_block, hog_channel, spatial_size,\n",
    "                                        hist_bins, spatial_feat, hist_feat, hog_feat)\n",
    "    print(\"features extracted\")\n",
    "    # in an image we are mostly going to find a lot of non-cars elements and\n",
    "    # few of cars. If we use balanced data, our data might start predicting\n",
    "    # more cars than needed. So, we need to 'balance' our dataset in a way\n",
    "    # that the classifier sees more non-car samples than car samples but not\n",
    "    # so less that it cannot learn the cars at all. One way of doing this in\n",
    "    # machine learning is to oversample one class that is expected more to be\n",
    "    #  seen in real scenario. We can double the sample space of non-cars dataset\n",
    "    X = np.vstack((car_features,\n",
    "                   non_car_features,\n",
    "                  non_car_features)).astype(np.float64)\n",
    "    # assigning labels to both classes where cars = 1 and non-cars = 0\n",
    "    # and also accommodating for the fact that the non-car elements are\n",
    "    # oversampled\n",
    "    y = np.hstack((np.ones(len(car_features)),\n",
    "                   np.zeros(2*len(non_car_features))))\n",
    "    print(\"Shape of data: \", X.shape)\n",
    "    print(\"Shape of labels: \", y.shape)\n",
    "    # normalizing the training set\n",
    "    scalar = StandardScaler()\n",
    "    # fitting the scalar to training data\n",
    "    scalar.fit(X)\n",
    "    # transforming the data according to the scalar\n",
    "    normalized_X = scalar.transform(X)\n",
    "    final_clf = LinearSVC()\n",
    "    # fitting the model on all the given\n",
    "    final_clf.fit(normalized_X, y)\n",
    "    \n",
    "    \n",
    "    # save the classifier\n",
    "    with open(color_space + '_linear_svm_best.pkl', 'wb') as final_model:\n",
    "        pickle.dump(final_clf, final_model)\n",
    "        \n",
    "    with open(color_space + \"_scaling_model.pkl\", \"wb\") as scalar_model:\n",
    "        pickle.dump(scalar, scalar_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features extracted\n",
      "Shape of data:  (26728, 8460)\n",
      "Shape of labels:  (26728,)\n"
     ]
    }
   ],
   "source": [
    "# final model on YCrCb\n",
    "final_model(cars, notcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
